\section{Training and evaluating setup}
\label{sec:training-and-evaluating-setup}
This section will outline the approaches taken in training (where applicable) the models developed in chapter~\ref{ch:methods}.

\subsection{Loading and pre-processing the dataset}
\label{subsec:loading-and-pre-processing-the-dataset}
As mentioned in section~\ref{subsec:data-pre-processing}, a PyTorch \verb|DataLoader| was used to label and load the images
for each classifier.
After the images were loaded, they were resized to the same $400 \times 400$ resolution, ensuring that most images are
enlarged rather than shrunk.
This was a conscious choice, as the textural features of some defects were quite small and harsh shrinking of the images
could have corrupted or outright removed that information.

After the images were set to a consistent size, the further processing differed slightly between the classifier types:
for the KNN classifier, no further processing was done.
This decision was based on the reasoning in section~\ref{subsec:knn-classifier} and aimed to preserve the colour values of the pixels.
For neural network-based classifiers, the processing consisted from a sequence of transforms from the Pytorch \verb|torchvision.transforms|
package and consisted of the following items:
\begin{itemize}
    \item Converting the images to the \verb|float32| data type to enable training on the M3 GPU cores
    \item For the training set, applying a random horizontal flip and a rotation to augment the dataset
    \item For the testing set, only applying a rotation to augment the test data due to its small size
\end{itemize}

After applying a stratified train/test split, with 80\% of images used for training, the class counts for the two sets are
shown in table~\ref{tab:finalTrainTestClassCuts}.
\begin{table}[h]
    \centering
    \begin{tabular}{lll}
        \toprule
        \textbf{Defect name} & \textbf{Training count} & \textbf{Testing count} \\
        \midrule
        Normal & 1048 & 263 \\
        Quaker & 782 & 196 \\
        Bean fragment & 237 & 59 \\
        Underroasted & 83 & 21 \\
        Burnt & 40 & 10 \\
        Insect/Mould & 38 & 9 \\
        \bottomrule
    \end{tabular}
    \caption{Finalised training and testing set class counts}
    \label{tab:finalTrainTestClassCuts}
\end{table}

TODO \cite{imbalancedSampler}
\subsection{KNN hyperparameter selection}
\label{subsec:knn-hyperparameter-selection}
\subsection{Neural network hyperparameter selection}
\label{subsec:neural-network-hyperparameter-selection}


\section{KNN classifier results}
\label{sec:knn-classifier-results}

\section{Compact CNN results}
\label{sec:compact-cnn-results}

\section{Transfer learning results}
\label{sec:transfer-learning-results}

\section{Evaluation}
\label{sec:evaluation}
