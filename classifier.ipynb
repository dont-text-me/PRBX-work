{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# This notebook aims to develop a neural-network based classifier for the coffee bean dataset\n",
    "## The technology of choice is pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T00:28:22.997039Z",
     "start_time": "2024-03-09T00:28:21.623836Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "bean_annotations = pd.read_csv(\"data/beans.csv\")\n",
    "bean_annotations.head()\n",
    "DEFECT_CLASSES = dict(\n",
    "    [\n",
    "        (defect, index)\n",
    "        for (index, defect) in enumerate(pd.unique(bean_annotations[\"defect_class\"]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T00:28:23.010303Z",
     "start_time": "2024-03-09T00:28:22.998211Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "transforms = {\n",
    "    \"train\": v2.Compose(\n",
    "        [\n",
    "            v2.Resize(size=(400, 400)),\n",
    "            v2.RandomHorizontalFlip(),\n",
    "            v2.RandomRotation(\n",
    "                degrees=(20, 340), fill=(255, 255, 255)\n",
    "            ),  # Augment the data with random rotations, setting the background to white\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"test\": v2.Compose(\n",
    "        [\n",
    "            v2.Resize(size=(400, 400)),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T00:28:23.014209Z",
     "start_time": "2024-03-09T00:28:23.011066Z"
    }
   },
   "outputs": [],
   "source": [
    "class RoastDefectsDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.bean_annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bean_annotations)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if torch.is_tensor(item):\n",
    "            item = item.toList()\n",
    "\n",
    "        img_name = self.bean_annotations.iloc[item, 0]\n",
    "        img_dir = \"-\".join(img_name.split(\"-\")[0:4])\n",
    "        img_path = os.path.join(self.root_dir, img_dir, img_name)\n",
    "        image = read_image(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        annotations = DEFECT_CLASSES[\n",
    "            self.bean_annotations.iloc[item, 1:][\"defect_class\"]\n",
    "        ]\n",
    "        return image, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T00:28:23.428960Z",
     "start_time": "2024-03-09T00:28:23.014858Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(bean_annotations, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T00:28:23.440773Z",
     "start_time": "2024-03-09T00:28:23.430548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                            img_name origin_country  variety  \\\ncount                                           2228           2228     2228   \nunique                                          2228              7        9   \ntop     ethiopia-ethHeirloom-washed-normal-17-19.png       ethiopia  caturra   \nfreq                                               1            785      711   \n\n       processing_method defect_class  \ncount               2228         2228  \nunique                 6            7  \ntop               washed       normal  \nfreq                1369         1044  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img_name</th>\n      <th>origin_country</th>\n      <th>variety</th>\n      <th>processing_method</th>\n      <th>defect_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2228</td>\n      <td>2228</td>\n      <td>2228</td>\n      <td>2228</td>\n      <td>2228</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2228</td>\n      <td>7</td>\n      <td>9</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>ethiopia-ethHeirloom-washed-normal-17-19.png</td>\n      <td>ethiopia</td>\n      <td>caturra</td>\n      <td>washed</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>785</td>\n      <td>711</td>\n      <td>1369</td>\n      <td>1044</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T00:28:23.447414Z",
     "start_time": "2024-03-09T00:28:23.441492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                    img_name origin_country  variety  \\\ncount                                    558            558      558   \nunique                                   558              7        9   \ntop     peru-caturra-washed-normal-18-16.png       ethiopia  caturra   \nfreq                                       1            192      186   \n\n       processing_method defect_class  \ncount                558          558  \nunique                 6            6  \ntop               washed       normal  \nfreq                 321          267  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img_name</th>\n      <th>origin_country</th>\n      <th>variety</th>\n      <th>processing_method</th>\n      <th>defect_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>558</td>\n      <td>558</td>\n      <td>558</td>\n      <td>558</td>\n      <td>558</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>558</td>\n      <td>7</td>\n      <td>9</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>peru-caturra-washed-normal-18-16.png</td>\n      <td>ethiopia</td>\n      <td>caturra</td>\n      <td>washed</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>192</td>\n      <td>186</td>\n      <td>321</td>\n      <td>267</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T00:28:23.455438Z",
     "start_time": "2024-03-09T00:28:23.448074Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "data_train = RoastDefectsDataset(\n",
    "    csv_file=\"data/beans.csv\", root_dir=\"data/processed\", transform=transforms[\"train\"]\n",
    ")\n",
    "\n",
    "data_test = RoastDefectsDataset(\n",
    "    csv_file=\"data/beans.csv\", root_dir=\"data/processed\", transform=transforms[\"test\"]\n",
    ")\n",
    "\n",
    "train_sampler = SubsetRandomSampler(list(train.index))\n",
    "test_sampler = SubsetRandomSampler(list(test.index))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(data_train, sampler=train_sampler, batch_size=64)\n",
    "test_loader = DataLoader(data_test, sampler=test_sampler, batch_size=64)\n",
    "\n",
    "dataloaders = {\"test\": test_loader, \"train\": train_loader}\n",
    "dataset_sizes = {\"test\": len(test), \"train\": len(train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T00:28:23.458013Z",
     "start_time": "2024-03-09T00:28:23.456228Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"mps\"  # Train on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T00:28:23.463440Z",
     "start_time": "2024-03-09T00:28:23.458711Z"
    }
   },
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "            print(\"-\" * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in [\"train\", \"test\"]:\n",
    "                if phase == \"train\":\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()  # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == \"train\"):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == \"train\":\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == \"train\":\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "                print(f\"Correct guesses in phase {phase}: {running_corrects}\")\n",
    "                print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == \"val\" and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        print(f\"Best val Acc: {best_acc:4f}\")\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T00:28:23.696780Z",
     "start_time": "2024-03-09T00:28:23.464171Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "model_ft = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(DEFECT_CLASSES))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T00:46:03.445597Z",
     "start_time": "2024-03-09T00:28:23.697902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "Correct guesses in phase train: 1282\n",
      "train Loss: 1.2471 Acc: 0.5754\n",
      "Correct guesses in phase test: 402\n",
      "test Loss: 0.9194 Acc: 0.7204\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "Correct guesses in phase train: 1666\n",
      "train Loss: 0.8006 Acc: 0.7478\n",
      "Correct guesses in phase test: 300\n",
      "test Loss: 1.0740 Acc: 0.5376\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "Correct guesses in phase train: 1724\n",
      "train Loss: 0.6876 Acc: 0.7738\n",
      "Correct guesses in phase test: 438\n",
      "test Loss: 0.6884 Acc: 0.7849\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "Correct guesses in phase train: 1773\n",
      "train Loss: 0.6021 Acc: 0.7958\n",
      "Correct guesses in phase test: 448\n",
      "test Loss: 0.6191 Acc: 0.8029\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "Correct guesses in phase train: 1822\n",
      "train Loss: 0.5399 Acc: 0.8178\n",
      "Correct guesses in phase test: 448\n",
      "test Loss: 0.5497 Acc: 0.8029\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "Correct guesses in phase train: 1857\n",
      "train Loss: 0.4775 Acc: 0.8335\n",
      "Correct guesses in phase test: 467\n",
      "test Loss: 0.4864 Acc: 0.8369\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "Correct guesses in phase train: 1893\n",
      "train Loss: 0.4434 Acc: 0.8496\n",
      "Correct guesses in phase test: 482\n",
      "test Loss: 0.4205 Acc: 0.8638\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "Correct guesses in phase train: 1922\n",
      "train Loss: 0.4037 Acc: 0.8627\n",
      "Correct guesses in phase test: 481\n",
      "test Loss: 0.4036 Acc: 0.8620\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "Correct guesses in phase train: 1923\n",
      "train Loss: 0.4025 Acc: 0.8631\n",
      "Correct guesses in phase test: 483\n",
      "test Loss: 0.3927 Acc: 0.8656\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "Correct guesses in phase train: 1934\n",
      "train Loss: 0.3987 Acc: 0.8680\n",
      "Correct guesses in phase test: 482\n",
      "test Loss: 0.3909 Acc: 0.8638\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "Correct guesses in phase train: 1930\n",
      "train Loss: 0.3854 Acc: 0.8662\n",
      "Correct guesses in phase test: 479\n",
      "test Loss: 0.3912 Acc: 0.8584\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "Correct guesses in phase train: 1932\n",
      "train Loss: 0.3827 Acc: 0.8671\n",
      "Correct guesses in phase test: 482\n",
      "test Loss: 0.3860 Acc: 0.8638\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "Correct guesses in phase train: 1950\n",
      "train Loss: 0.3651 Acc: 0.8752\n",
      "Correct guesses in phase test: 484\n",
      "test Loss: 0.3851 Acc: 0.8674\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "Correct guesses in phase train: 1941\n",
      "train Loss: 0.3732 Acc: 0.8712\n",
      "Correct guesses in phase test: 486\n",
      "test Loss: 0.3747 Acc: 0.8710\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "Correct guesses in phase train: 1947\n",
      "train Loss: 0.3700 Acc: 0.8739\n",
      "Correct guesses in phase test: 484\n",
      "test Loss: 0.3767 Acc: 0.8674\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "Correct guesses in phase train: 1937\n",
      "train Loss: 0.3688 Acc: 0.8694\n",
      "Correct guesses in phase test: 481\n",
      "test Loss: 0.3781 Acc: 0.8620\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "Correct guesses in phase train: 1944\n",
      "train Loss: 0.3625 Acc: 0.8725\n",
      "Correct guesses in phase test: 485\n",
      "test Loss: 0.3738 Acc: 0.8692\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "Correct guesses in phase train: 1950\n",
      "train Loss: 0.3635 Acc: 0.8752\n",
      "Correct guesses in phase test: 485\n",
      "test Loss: 0.3786 Acc: 0.8692\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "Correct guesses in phase train: 1955\n",
      "train Loss: 0.3698 Acc: 0.8775\n",
      "Correct guesses in phase test: 483\n",
      "test Loss: 0.3789 Acc: 0.8656\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "Correct guesses in phase train: 1942\n",
      "train Loss: 0.3736 Acc: 0.8716\n",
      "Correct guesses in phase test: 489\n",
      "test Loss: 0.3742 Acc: 0.8763\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "Correct guesses in phase train: 1942\n",
      "train Loss: 0.3789 Acc: 0.8716\n",
      "Correct guesses in phase test: 487\n",
      "test Loss: 0.3732 Acc: 0.8728\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "Correct guesses in phase train: 1961\n",
      "train Loss: 0.3577 Acc: 0.8802\n",
      "Correct guesses in phase test: 483\n",
      "test Loss: 0.3792 Acc: 0.8656\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "Correct guesses in phase train: 1957\n",
      "train Loss: 0.3602 Acc: 0.8784\n",
      "Correct guesses in phase test: 485\n",
      "test Loss: 0.3772 Acc: 0.8692\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "Correct guesses in phase train: 1953\n",
      "train Loss: 0.3597 Acc: 0.8766\n",
      "Correct guesses in phase test: 484\n",
      "test Loss: 0.3806 Acc: 0.8674\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "Correct guesses in phase train: 1931\n",
      "train Loss: 0.3781 Acc: 0.8667\n",
      "Correct guesses in phase test: 489\n",
      "test Loss: 0.3716 Acc: 0.8763\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "Correct guesses in phase train: 1959\n",
      "train Loss: 0.3675 Acc: 0.8793\n",
      "Correct guesses in phase test: 489\n",
      "test Loss: 0.3746 Acc: 0.8763\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "Correct guesses in phase train: 1962\n",
      "train Loss: 0.3653 Acc: 0.8806\n",
      "Correct guesses in phase test: 485\n",
      "test Loss: 0.3779 Acc: 0.8692\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "Correct guesses in phase train: 1946\n",
      "train Loss: 0.3706 Acc: 0.8734\n",
      "Correct guesses in phase test: 481\n",
      "test Loss: 0.3846 Acc: 0.8620\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "Correct guesses in phase train: 1941\n",
      "train Loss: 0.3655 Acc: 0.8712\n",
      "Correct guesses in phase test: 485\n",
      "test Loss: 0.3803 Acc: 0.8692\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "Correct guesses in phase train: 1960\n",
      "train Loss: 0.3679 Acc: 0.8797\n",
      "Correct guesses in phase test: 483\n",
      "test Loss: 0.3804 Acc: 0.8656\n",
      "\n",
      "Best val Acc: 0.000000\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(\n",
    "    model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=30\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
