{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# This notebook aims to develop a neural-network based classifier for the coffee bean dataset\n",
    "## The technology of choice is pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T21:09:34.355704Z",
     "start_time": "2024-03-08T21:09:34.347284Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "bean_annotations = pd.read_csv(\"data/beans.csv\")\n",
    "bean_annotations.head()\n",
    "DEFECT_CLASSES = dict(\n",
    "    [\n",
    "        (defect, index)\n",
    "        for (index, defect) in enumerate(pd.unique(bean_annotations[\"defect_class\"]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T21:09:34.360916Z",
     "start_time": "2024-03-08T21:09:34.357162Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "transforms = {\n",
    "    \"train\": v2.Compose(\n",
    "        [\n",
    "            v2.Resize(size=(400, 400)),\n",
    "            v2.RandomHorizontalFlip(),\n",
    "            v2.RandomRotation(\n",
    "                degrees=(20, 340), fill=(255, 255, 255)\n",
    "            ),  # Augment the data with random rotations, setting the background to white\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"test\": v2.Compose(\n",
    "        [\n",
    "            v2.Resize(size=(400, 400)),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T21:09:34.365890Z",
     "start_time": "2024-03-08T21:09:34.362175Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RoastDefectsDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.bean_annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bean_annotations)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if torch.is_tensor(item):\n",
    "            item = item.toList()\n",
    "\n",
    "        img_name = self.bean_annotations.iloc[item, 0]\n",
    "        img_dir = \"-\".join(img_name.split(\"-\")[0:4])\n",
    "        img_path = os.path.join(self.root_dir, img_dir, img_name)\n",
    "        image = read_image(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        annotations = DEFECT_CLASSES[\n",
    "            self.bean_annotations.iloc[item, 1:][\"defect_class\"]\n",
    "        ]\n",
    "        return image, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T21:09:34.369420Z",
     "start_time": "2024-03-08T21:09:34.366793Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(bean_annotations, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T21:09:34.378092Z",
     "start_time": "2024-03-08T21:09:34.370742Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img_name</th>\n      <th>origin_country</th>\n      <th>variety</th>\n      <th>processing_method</th>\n      <th>defect_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2507</td>\n      <td>2507</td>\n      <td>2507</td>\n      <td>2507</td>\n      <td>2507</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2507</td>\n      <td>7</td>\n      <td>9</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>brazil-wushwush-nat-frag-0-7.png</td>\n      <td>ethiopia</td>\n      <td>caturra</td>\n      <td>washed</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>878</td>\n      <td>816</td>\n      <td>1515</td>\n      <td>1179</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                img_name origin_country  variety  \\\ncount                               2507           2507     2507   \nunique                              2507              7        9   \ntop     brazil-wushwush-nat-frag-0-7.png       ethiopia  caturra   \nfreq                                   1            878      816   \n\n       processing_method defect_class  \ncount               2507         2507  \nunique                 6            7  \ntop               washed       normal  \nfreq                1515         1179  "
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T21:09:34.384734Z",
     "start_time": "2024-03-08T21:09:34.378766Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img_name</th>\n      <th>origin_country</th>\n      <th>variety</th>\n      <th>processing_method</th>\n      <th>defect_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>279</td>\n      <td>279</td>\n      <td>279</td>\n      <td>279</td>\n      <td>279</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>279</td>\n      <td>7</td>\n      <td>9</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>kenya-sl28-washed-quaker-5-12.png</td>\n      <td>ethiopia</td>\n      <td>caturra</td>\n      <td>washed</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>99</td>\n      <td>81</td>\n      <td>175</td>\n      <td>132</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                 img_name origin_country  variety  \\\ncount                                 279            279      279   \nunique                                279              7        9   \ntop     kenya-sl28-washed-quaker-5-12.png       ethiopia  caturra   \nfreq                                    1             99       81   \n\n       processing_method defect_class  \ncount                279          279  \nunique                 6            6  \ntop               washed       normal  \nfreq                 175          132  "
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T21:09:34.395334Z",
     "start_time": "2024-03-08T21:09:34.385615Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "data_train = RoastDefectsDataset(\n",
    "    csv_file=\"data/beans.csv\", root_dir=\"data/processed\", transform=transforms[\"train\"]\n",
    ")\n",
    "\n",
    "data_test = RoastDefectsDataset(\n",
    "    csv_file=\"data/beans.csv\", root_dir=\"data/processed\", transform=transforms[\"test\"]\n",
    ")\n",
    "\n",
    "train_sampler = SubsetRandomSampler(list(train.index))\n",
    "test_sampler = SubsetRandomSampler(list(test.index))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(data_train, sampler=train_sampler, batch_size=64)\n",
    "test_loader = DataLoader(data_test, sampler=test_sampler, batch_size=64)\n",
    "\n",
    "dataloaders = {\"test\": test_loader, \"train\": train_loader}\n",
    "dataset_sizes = {\"test\": len(test), \"train\": len(train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T21:09:34.401708Z",
     "start_time": "2024-03-08T21:09:34.396702Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = \"mps\"  # Train on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T21:27:36.301728Z",
     "start_time": "2024-03-08T21:27:36.294801Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "            print(\"-\" * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in [\"train\", \"test\"]:\n",
    "                if phase == \"train\":\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()  # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == \"train\"):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == \"train\":\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == \"train\":\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "                print(f\"Correct guesses in phase {phase}: {running_corrects}\")\n",
    "                print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == \"val\" and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        print(f\"Best val Acc: {best_acc:4f}\")\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T21:27:37.665394Z",
     "start_time": "2024-03-08T21:27:37.444310Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "model_ft = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-08T21:30:20.098001Z",
     "start_time": "2024-03-08T21:27:39.226485Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "Correct guesses in phase train: 34\n",
      "train Loss: 0.0098 Acc: 0.0136\n",
      "Correct guesses in phase test: 2\n",
      "test Loss: 0.0016 Acc: 0.0072\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "Correct guesses in phase train: 48\n",
      "train Loss: 0.0019 Acc: 0.0191\n",
      "Correct guesses in phase test: 2\n",
      "test Loss: 0.0008 Acc: 0.0072\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "Correct guesses in phase train: 48\n",
      "train Loss: 0.0011 Acc: 0.0191\n",
      "Correct guesses in phase test: 2\n",
      "test Loss: 0.0006 Acc: 0.0072\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "Correct guesses in phase train: 48\n",
      "train Loss: 0.0008 Acc: 0.0191\n",
      "Correct guesses in phase test: 2\n",
      "test Loss: 0.0004 Acc: 0.0072\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[196], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_ft \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_lr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[194], line 47\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# statistics\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     48\u001b[0m     running_corrects \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(preds \u001b[38;5;241m==\u001b[39m labels\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = train_model(\n",
    "    model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
