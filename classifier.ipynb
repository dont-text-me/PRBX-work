{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# This notebook aims to develop a neural-network based classifier for the coffee bean dataset\n",
    "## The technology of choice is pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T21:34:51.711968Z",
     "start_time": "2024-03-08T21:34:51.704985Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "bean_annotations = pd.read_csv(\"data/beans.csv\")\n",
    "bean_annotations.head()\n",
    "DEFECT_CLASSES = dict(\n",
    "    [\n",
    "        (defect, index)\n",
    "        for (index, defect) in enumerate(pd.unique(bean_annotations[\"defect_class\"]))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T21:34:51.723042Z",
     "start_time": "2024-03-08T21:34:51.719651Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "transforms = {\n",
    "    \"train\": v2.Compose(\n",
    "        [\n",
    "            v2.Resize(size=(400, 400)),\n",
    "            v2.RandomHorizontalFlip(),\n",
    "            v2.RandomRotation(\n",
    "                degrees=(20, 340), fill=(255, 255, 255)\n",
    "            ),  # Augment the data with random rotations, setting the background to white\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"test\": v2.Compose(\n",
    "        [\n",
    "            v2.Resize(size=(400, 400)),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T21:34:51.736377Z",
     "start_time": "2024-03-08T21:34:51.732897Z"
    }
   },
   "outputs": [],
   "source": [
    "class RoastDefectsDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.bean_annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bean_annotations)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if torch.is_tensor(item):\n",
    "            item = item.toList()\n",
    "\n",
    "        img_name = self.bean_annotations.iloc[item, 0]\n",
    "        img_dir = \"-\".join(img_name.split(\"-\")[0:4])\n",
    "        img_path = os.path.join(self.root_dir, img_dir, img_name)\n",
    "        image = read_image(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        annotations = DEFECT_CLASSES[\n",
    "            self.bean_annotations.iloc[item, 1:][\"defect_class\"]\n",
    "        ]\n",
    "        return image, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T21:34:51.740202Z",
     "start_time": "2024-03-08T21:34:51.737280Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(bean_annotations, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T21:34:51.748507Z",
     "start_time": "2024-03-08T21:34:51.741192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                        img_name origin_country  variety  \\\ncount                                       2507           2507     2507   \nunique                                      2507              7        9   \ntop     ecuador-typica-anaerobicNat-frag-1-6.png       ethiopia  caturra   \nfreq                                           1            890      807   \n\n       processing_method defect_class  \ncount               2507         2507  \nunique                 6            7  \ntop               washed       normal  \nfreq                1532         1199  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img_name</th>\n      <th>origin_country</th>\n      <th>variety</th>\n      <th>processing_method</th>\n      <th>defect_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2507</td>\n      <td>2507</td>\n      <td>2507</td>\n      <td>2507</td>\n      <td>2507</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2507</td>\n      <td>7</td>\n      <td>9</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>ecuador-typica-anaerobicNat-frag-1-6.png</td>\n      <td>ethiopia</td>\n      <td>caturra</td>\n      <td>washed</td>\n      <td>normal</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>890</td>\n      <td>807</td>\n      <td>1532</td>\n      <td>1199</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T21:34:51.755595Z",
     "start_time": "2024-03-08T21:34:51.749553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                 img_name origin_country  variety  \\\ncount                                 279            279      279   \nunique                                279              7        9   \ntop     brazil-catuai-nat-quaker-2-10.png       ethiopia  caturra   \nfreq                                    1             87       90   \n\n       processing_method defect_class  \ncount                279          279  \nunique                 6            6  \ntop               washed       quaker  \nfreq                 158          118  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img_name</th>\n      <th>origin_country</th>\n      <th>variety</th>\n      <th>processing_method</th>\n      <th>defect_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>279</td>\n      <td>279</td>\n      <td>279</td>\n      <td>279</td>\n      <td>279</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>279</td>\n      <td>7</td>\n      <td>9</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>brazil-catuai-nat-quaker-2-10.png</td>\n      <td>ethiopia</td>\n      <td>caturra</td>\n      <td>washed</td>\n      <td>quaker</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>87</td>\n      <td>90</td>\n      <td>158</td>\n      <td>118</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T21:34:51.764511Z",
     "start_time": "2024-03-08T21:34:51.756326Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "data_train = RoastDefectsDataset(\n",
    "    csv_file=\"data/beans.csv\", root_dir=\"data/processed\", transform=transforms[\"train\"]\n",
    ")\n",
    "\n",
    "data_test = RoastDefectsDataset(\n",
    "    csv_file=\"data/beans.csv\", root_dir=\"data/processed\", transform=transforms[\"test\"]\n",
    ")\n",
    "\n",
    "train_sampler = SubsetRandomSampler(list(train.index))\n",
    "test_sampler = SubsetRandomSampler(list(test.index))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(data_train, sampler=train_sampler, batch_size=64)\n",
    "test_loader = DataLoader(data_test, sampler=test_sampler, batch_size=64)\n",
    "\n",
    "dataloaders = {\"test\": test_loader, \"train\": train_loader}\n",
    "dataset_sizes = {\"test\": len(test), \"train\": len(train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T21:34:51.766803Z",
     "start_time": "2024-03-08T21:34:51.765182Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"mps\"  # Train on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T21:34:51.778160Z",
     "start_time": "2024-03-08T21:34:51.767576Z"
    }
   },
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "            print(\"-\" * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in [\"train\", \"test\"]:\n",
    "                if phase == \"train\":\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()  # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == \"train\"):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == \"train\":\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == \"train\":\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "                print(f\"Correct guesses in phase {phase}: {running_corrects}\")\n",
    "                print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == \"val\" and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        print(f\"Best val Acc: {best_acc:4f}\")\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T21:34:52.075729Z",
     "start_time": "2024-03-08T21:34:51.787559Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "model_ft = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(DEFECT_CLASSES))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T21:50:41.907510Z",
     "start_time": "2024-03-08T21:34:52.076606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "Correct guesses in phase train: 1476\n",
      "train Loss: 1.1908 Acc: 0.5888\n",
      "Correct guesses in phase test: 179\n",
      "test Loss: 1.0577 Acc: 0.6416\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "Correct guesses in phase train: 1897\n",
      "train Loss: 0.7586 Acc: 0.7567\n",
      "Correct guesses in phase test: 198\n",
      "test Loss: 0.8726 Acc: 0.7097\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "Correct guesses in phase train: 1979\n",
      "train Loss: 0.6444 Acc: 0.7894\n",
      "Correct guesses in phase test: 206\n",
      "test Loss: 0.7373 Acc: 0.7384\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "Correct guesses in phase train: 2008\n",
      "train Loss: 0.5765 Acc: 0.8010\n",
      "Correct guesses in phase test: 217\n",
      "test Loss: 0.6185 Acc: 0.7778\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "Correct guesses in phase train: 2058\n",
      "train Loss: 0.5295 Acc: 0.8209\n",
      "Correct guesses in phase test: 221\n",
      "test Loss: 0.5825 Acc: 0.7921\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "Correct guesses in phase train: 2085\n",
      "train Loss: 0.4844 Acc: 0.8317\n",
      "Correct guesses in phase test: 226\n",
      "test Loss: 0.5889 Acc: 0.8100\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "Correct guesses in phase train: 2122\n",
      "train Loss: 0.4293 Acc: 0.8464\n",
      "Correct guesses in phase test: 229\n",
      "test Loss: 0.5111 Acc: 0.8208\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "Correct guesses in phase train: 2167\n",
      "train Loss: 0.3936 Acc: 0.8644\n",
      "Correct guesses in phase test: 232\n",
      "test Loss: 0.4978 Acc: 0.8315\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "Correct guesses in phase train: 2181\n",
      "train Loss: 0.3874 Acc: 0.8700\n",
      "Correct guesses in phase test: 229\n",
      "test Loss: 0.4958 Acc: 0.8208\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "Correct guesses in phase train: 2176\n",
      "train Loss: 0.3816 Acc: 0.8680\n",
      "Correct guesses in phase test: 231\n",
      "test Loss: 0.5032 Acc: 0.8280\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "Correct guesses in phase train: 2175\n",
      "train Loss: 0.3706 Acc: 0.8676\n",
      "Correct guesses in phase test: 231\n",
      "test Loss: 0.4917 Acc: 0.8280\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "Correct guesses in phase train: 2174\n",
      "train Loss: 0.3711 Acc: 0.8672\n",
      "Correct guesses in phase test: 230\n",
      "test Loss: 0.4927 Acc: 0.8244\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "Correct guesses in phase train: 2173\n",
      "train Loss: 0.3774 Acc: 0.8668\n",
      "Correct guesses in phase test: 234\n",
      "test Loss: 0.4888 Acc: 0.8387\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "Correct guesses in phase train: 2180\n",
      "train Loss: 0.3715 Acc: 0.8696\n",
      "Correct guesses in phase test: 231\n",
      "test Loss: 0.4899 Acc: 0.8280\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "Correct guesses in phase train: 2201\n",
      "train Loss: 0.3622 Acc: 0.8779\n",
      "Correct guesses in phase test: 231\n",
      "test Loss: 0.4908 Acc: 0.8280\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "Correct guesses in phase train: 2191\n",
      "train Loss: 0.3637 Acc: 0.8740\n",
      "Correct guesses in phase test: 231\n",
      "test Loss: 0.4893 Acc: 0.8280\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "Correct guesses in phase train: 2202\n",
      "train Loss: 0.3645 Acc: 0.8783\n",
      "Correct guesses in phase test: 230\n",
      "test Loss: 0.4837 Acc: 0.8244\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "Correct guesses in phase train: 2193\n",
      "train Loss: 0.3619 Acc: 0.8748\n",
      "Correct guesses in phase test: 232\n",
      "test Loss: 0.4826 Acc: 0.8315\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "Correct guesses in phase train: 2192\n",
      "train Loss: 0.3684 Acc: 0.8744\n",
      "Correct guesses in phase test: 231\n",
      "test Loss: 0.4878 Acc: 0.8280\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "Correct guesses in phase train: 2180\n",
      "train Loss: 0.3758 Acc: 0.8696\n",
      "Correct guesses in phase test: 232\n",
      "test Loss: 0.4831 Acc: 0.8315\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "Correct guesses in phase train: 2181\n",
      "train Loss: 0.3573 Acc: 0.8700\n",
      "Correct guesses in phase test: 232\n",
      "test Loss: 0.4821 Acc: 0.8315\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "Correct guesses in phase train: 2183\n",
      "train Loss: 0.3698 Acc: 0.8708\n",
      "Correct guesses in phase test: 232\n",
      "test Loss: 0.4831 Acc: 0.8315\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "Correct guesses in phase train: 2188\n",
      "train Loss: 0.3697 Acc: 0.8728\n",
      "Correct guesses in phase test: 231\n",
      "test Loss: 0.4923 Acc: 0.8280\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "Correct guesses in phase train: 2208\n",
      "train Loss: 0.3598 Acc: 0.8807\n",
      "Correct guesses in phase test: 231\n",
      "test Loss: 0.4834 Acc: 0.8280\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "Correct guesses in phase train: 2200\n",
      "train Loss: 0.3700 Acc: 0.8775\n",
      "Correct guesses in phase test: 231\n",
      "test Loss: 0.4863 Acc: 0.8280\n",
      "\n",
      "Best val Acc: 0.000000\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(\n",
    "    model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T21:50:41.909662Z",
     "start_time": "2024-03-08T21:50:41.908379Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
